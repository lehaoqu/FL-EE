alg: darkflpa2
policy: boosted
dataset: speechcmds
model: vit
config_path: models/facebook/deit-tiny-patch16-224
ft: full
load_path: 
seed: 1117
total_num: 100
sr: 0.1
suffix: EXPS/BASE_SPEECHCMDS/full_boosted
device: 3
rnd: 500
bs: 32
epoch: 1
lr: 0.05
gamma: 0.99
optim: sgd
valid_gap: 10
eq_ratios: (0.25, 0.25, 0.25, 0.25)
eq_depths: (3, 6, 9, 12)
multi_exit: False
if_mode: all
cosine: False
valid_ratio: 0.2
eval_models_dir: script/0818-1e-1
eval_test: False
noise: -1
hidden_dim: -1
is_latent: True
s_epoches: 1
s_bs: 32
adaptive_epoches: False
kd_skip: 1
kd_begin: 0
kd_lr: 0.05
kd_response_ratio: 3
kd_dist_ratio: 5
kd_angle_ratio: 10
kd_dark_ratio: 0
kd_n_iters: 5
kd_gap: 1
g_skip: 1
g_begin: 0
g_lr: 0.01
g_y: 1
g_div: 1
g_gap: 1
g_diff: 1
g_n_iters: 1
kd_direction: sl
kd_join: last
agg: after
loss_type: kd
dm: loss
diff_client_gap: 1
diff_generator: False
sw: learn
sw_type: soft
exit_p: 30
s_gamma: 1
wd: 0.001
increase: True
ensemble_weight: 0.2
output: <_io.TextIOWrapper name='./EXPS/BASE_SPEECHCMDS/full_boosted/darkflpa2_speechcmds_vit_100c_1E_lrsgd0.05_boosted.txt' mode='a' encoding='UTF-8'>
========== Round 0 ==========
server, accuracy: 6.80, exits:['3.86', '4.94', '10.76', '7.66'] loss: 9.96
========== Round 10 ==========
server, accuracy: 71.21, exits:['50.11', '77.23', '79.13', '78.37'] loss: 3.50
========== Round 20 ==========
server, accuracy: 84.74, exits:['75.09', '87.76', '88.27', '87.86'] loss: 1.86
========== Round 30 ==========
server, accuracy: 88.05, exits:['81.80', '89.68', '90.55', '90.17'] loss: 1.30
========== Round 40 ==========
server, accuracy: 89.74, exits:['85.45', '91.26', '91.51', '90.74'] loss: 1.01
========== Round 50 ==========
server, accuracy: 90.99, exits:['87.47', '92.10', '92.42', '91.96'] loss: 0.94
========== Round 60 ==========
server, accuracy: 91.95, exits:['88.99', '92.92', '93.10', '92.79'] loss: 0.66
========== Round 70 ==========
server, accuracy: 92.14, exits:['89.58', '93.03', '93.18', '92.79'] loss: 0.55
========== Round 80 ==========
server, accuracy: 92.46, exits:['89.98', '93.30', '93.39', '93.17'] loss: 0.50
========== Round 90 ==========
server, accuracy: 93.07, exits:['90.81', '93.86', '93.91', '93.68'] loss: 0.52
========== Round 100 ==========
server, accuracy: 93.16, exits:['90.93', '93.90', '93.97', '93.82'] loss: 0.39
========== Round 110 ==========
server, accuracy: 93.26, exits:['91.26', '94.00', '94.05', '93.74'] loss: 0.33
========== Round 120 ==========
server, accuracy: 93.23, exits:['91.34', '93.99', '93.87', '93.72'] loss: 0.34
========== Round 130 ==========
server, accuracy: 93.60, exits:['91.91', '94.20', '94.22', '94.06'] loss: 0.35
========== Round 140 ==========
server, accuracy: 93.63, exits:['91.91', '94.24', '94.33', '94.04'] loss: 0.25
========== Round 150 ==========
server, accuracy: 93.57, exits:['92.06', '94.20', '94.09', '93.92'] loss: 0.29
========== Round 160 ==========
server, accuracy: 93.75, exits:['92.21', '94.37', '94.25', '94.15'] loss: 0.28
========== Round 170 ==========
server, accuracy: 93.75, exits:['92.29', '94.35', '94.30', '94.07'] loss: 0.24
========== Round 180 ==========
server, accuracy: 93.83, exits:['92.36', '94.45', '94.40', '94.11'] loss: 0.24
========== Round 190 ==========
server, accuracy: 93.75, exits:['92.38', '94.33', '94.21', '94.07'] loss: 0.24
========== Round 200 ==========
server, accuracy: 93.83, exits:['92.38', '94.44', '94.37', '94.12'] loss: 0.16
========== Round 202 ==========
server, accuracy: 93.85, exits:['92.49', '94.44', '94.29', '94.18'] loss: 0.19
========== Round 204 ==========
server, accuracy: 93.87, exits:['92.51', '94.50', '94.35', '94.12'] loss: 0.22
========== Round 206 ==========
server, accuracy: 93.88, exits:['92.53', '94.44', '94.40', '94.15'] loss: 0.21
========== Round 208 ==========
server, accuracy: 93.86, exits:['92.47', '94.44', '94.39', '94.13'] loss: 0.20
========== Round 210 ==========
server, accuracy: 93.86, exits:['92.59', '94.36', '94.40', '94.08'] loss: 0.21
========== Round 212 ==========
server, accuracy: 93.92, exits:['92.66', '94.45', '94.41', '94.14'] loss: 0.19
========== Round 214 ==========
server, accuracy: 93.86, exits:['92.52', '94.45', '94.32', '94.13'] loss: 0.20
========== Round 216 ==========
server, accuracy: 93.93, exits:['92.67', '94.45', '94.46', '94.15'] loss: 0.23
========== Round 218 ==========
server, accuracy: 93.90, exits:['92.56', '94.42', '94.42', '94.20'] loss: 0.17
========== Round 220 ==========
server, accuracy: 93.87, exits:['92.52', '94.32', '94.40', '94.23'] loss: 0.20
========== Round 222 ==========
server, accuracy: 93.81, exits:['92.55', '94.42', '94.21', '94.04'] loss: 0.18
========== Round 224 ==========
server, accuracy: 93.90, exits:['92.56', '94.46', '94.38', '94.21'] loss: 0.20
========== Round 226 ==========
server, accuracy: 93.83, exits:['92.41', '94.42', '94.39', '94.12'] loss: 0.19
========== Round 228 ==========
server, accuracy: 93.93, exits:['92.59', '94.55', '94.40', '94.19'] loss: 0.15
========== Round 230 ==========
server, accuracy: 93.84, exits:['92.47', '94.35', '94.41', '94.14'] loss: 0.20
========== Round 232 ==========
server, accuracy: 93.72, exits:['92.44', '94.29', '94.17', '93.98'] loss: 0.15
========== Round 234 ==========
server, accuracy: 93.98, exits:['92.63', '94.56', '94.56', '94.18'] loss: 0.17
========== Round 236 ==========
server, accuracy: 93.91, exits:['92.48', '94.44', '94.43', '94.30'] loss: 0.20
========== Round 238 ==========
server, accuracy: 93.98, exits:['92.58', '94.56', '94.55', '94.23'] loss: 0.16
========== Round 240 ==========
server, accuracy: 93.95, exits:['92.62', '94.46', '94.44', '94.29'] loss: 0.16
========== Round 242 ==========
server, accuracy: 93.95, exits:['92.52', '94.59', '94.40', '94.28'] loss: 0.16
========== Round 244 ==========
server, accuracy: 93.93, exits:['92.57', '94.50', '94.42', '94.23'] loss: 0.15
========== Round 246 ==========
server, accuracy: 93.93, exits:['92.63', '94.46', '94.39', '94.24'] loss: 0.14
