alg: darkflpa2
policy: base
dataset: speechcmds
model: vit
config_path: models/facebook/deit-tiny-patch16-224
ft: full
load_path: 
seed: 1117
total_num: 100
sr: 0.1
suffix: EXPS/BASE_SPEECHCMDS/full_base
device: 2
rnd: 500
bs: 32
epoch: 1
lr: 0.05
gamma: 0.99
optim: sgd
valid_gap: 10
eq_ratios: (0.25, 0.25, 0.25, 0.25)
eq_depths: (3, 6, 9, 12)
multi_exit: False
if_mode: all
cosine: False
valid_ratio: 0.2
eval_models_dir: script/0818-1e-1
eval_test: False
noise: -1
hidden_dim: -1
is_latent: True
s_epoches: 1
s_bs: 32
adaptive_epoches: False
kd_skip: 1
kd_begin: 0
kd_lr: 0.05
kd_response_ratio: 3
kd_dist_ratio: 5
kd_angle_ratio: 10
kd_dark_ratio: 0
kd_n_iters: 5
kd_gap: 1
g_skip: 1
g_begin: 0
g_lr: 0.01
g_y: 1
g_div: 1
g_gap: 1
g_diff: 1
g_n_iters: 1
kd_direction: sl
kd_join: last
agg: after
loss_type: kd
dm: loss
diff_client_gap: 1
diff_generator: False
sw: learn
sw_type: soft
exit_p: 30
s_gamma: 1
wd: 0.001
increase: True
output: <_io.TextIOWrapper name='./EXPS/BASE_SPEECHCMDS/full_base/darkflpa2_speechcmds_vit_100c_1E_lrsgd0.05_base.txt' mode='a' encoding='UTF-8'>
========== Round 0 ==========
server, accuracy: 3.72, exits:['3.98', '3.87', '3.09', '3.93'] loss: 10.01
========== Round 10 ==========
server, accuracy: 23.28, exits:['21.25', '25.54', '24.67', '21.65'] loss: 7.77
========== Round 20 ==========
server, accuracy: 69.82, exits:['59.44', '74.27', '73.88', '71.71'] loss: 4.27
========== Round 30 ==========
server, accuracy: 80.89, exits:['73.62', '83.47', '83.47', '83.01'] loss: 2.33
========== Round 40 ==========
server, accuracy: 85.76, exits:['80.73', '87.42', '87.67', '87.22'] loss: 1.71
========== Round 50 ==========
server, accuracy: 87.97, exits:['83.71', '89.47', '89.73', '88.98'] loss: 1.50
========== Round 60 ==========
server, accuracy: 89.61, exits:['86.06', '90.72', '90.98', '90.70'] loss: 1.00
========== Round 70 ==========
server, accuracy: 89.69, exits:['86.75', '90.83', '90.63', '90.54'] loss: 0.93
========== Round 80 ==========
server, accuracy: 90.96, exits:['88.10', '91.95', '92.08', '91.71'] loss: 0.73
========== Round 90 ==========
server, accuracy: 91.37, exits:['88.63', '92.24', '92.35', '92.24'] loss: 0.78
========== Round 100 ==========
server, accuracy: 91.84, exits:['89.30', '92.62', '92.87', '92.57'] loss: 0.53
========== Round 110 ==========
server, accuracy: 92.17, exits:['89.84', '92.83', '93.04', '92.95'] loss: 0.47
========== Round 120 ==========
server, accuracy: 92.50, exits:['90.30', '93.15', '93.36', '93.19'] loss: 0.51
========== Round 130 ==========
server, accuracy: 92.62, exits:['90.51', '93.17', '93.45', '93.36'] loss: 0.51
========== Round 140 ==========
server, accuracy: 92.51, exits:['90.51', '93.13', '93.20', '93.19'] loss: 0.41
========== Round 150 ==========
server, accuracy: 92.65, exits:['90.77', '93.20', '93.39', '93.25'] loss: 0.43
========== Round 160 ==========
server, accuracy: 92.85, exits:['91.04', '93.43', '93.50', '93.42'] loss: 0.37
========== Round 170 ==========
server, accuracy: 92.97, exits:['91.39', '93.43', '93.61', '93.44'] loss: 0.31
========== Round 180 ==========
server, accuracy: 92.90, exits:['91.29', '93.31', '93.60', '93.41'] loss: 0.32
========== Round 190 ==========
server, accuracy: 93.01, exits:['91.42', '93.49', '93.62', '93.53'] loss: 0.27
========== Round 200 ==========
server, accuracy: 93.05, exits:['91.66', '93.48', '93.52', '93.55'] loss: 0.21
========== Round 202 ==========
server, accuracy: 93.05, exits:['91.43', '93.54', '93.63', '93.58'] loss: 0.25
========== Round 204 ==========
server, accuracy: 93.11, exits:['91.54', '93.55', '93.69', '93.64'] loss: 0.24
========== Round 206 ==========
server, accuracy: 93.13, exits:['91.70', '93.59', '93.65', '93.60'] loss: 0.22
========== Round 208 ==========
server, accuracy: 93.10, exits:['91.58', '93.60', '93.66', '93.56'] loss: 0.25
========== Round 210 ==========
server, accuracy: 93.16, exits:['91.66', '93.60', '93.73', '93.66'] loss: 0.26
========== Round 212 ==========
server, accuracy: 93.17, exits:['91.67', '93.60', '93.76', '93.63'] loss: 0.26
========== Round 214 ==========
server, accuracy: 93.21, exits:['91.71', '93.70', '93.74', '93.68'] loss: 0.25
========== Round 216 ==========
server, accuracy: 93.20, exits:['91.69', '93.65', '93.78', '93.67'] loss: 0.26
========== Round 218 ==========
server, accuracy: 93.13, exits:['91.72', '93.57', '93.64', '93.60'] loss: 0.23
========== Round 220 ==========
server, accuracy: 93.16, exits:['91.82', '93.54', '93.64', '93.64'] loss: 0.25
========== Round 222 ==========
server, accuracy: 93.20, exits:['91.79', '93.60', '93.71', '93.69'] loss: 0.23
========== Round 224 ==========
server, accuracy: 93.15, exits:['91.70', '93.60', '93.66', '93.63'] loss: 0.21
========== Round 226 ==========
server, accuracy: 93.15, exits:['91.72', '93.59', '93.65', '93.64'] loss: 0.25
========== Round 228 ==========
server, accuracy: 93.18, exits:['91.74', '93.63', '93.71', '93.66'] loss: 0.17
========== Round 230 ==========
server, accuracy: 93.16, exits:['91.71', '93.57', '93.71', '93.65'] loss: 0.23
========== Round 232 ==========
server, accuracy: 93.11, exits:['91.60', '93.53', '93.70', '93.60'] loss: 0.17
========== Round 234 ==========
server, accuracy: 93.11, exits:['91.65', '93.51', '93.69', '93.61'] loss: 0.17
========== Round 236 ==========
server, accuracy: 93.19, exits:['91.78', '93.64', '93.69', '93.64'] loss: 0.23
========== Round 238 ==========
server, accuracy: 93.18, exits:['91.80', '93.53', '93.72', '93.69'] loss: 0.20
========== Round 240 ==========
server, accuracy: 93.12, exits:['91.77', '93.51', '93.60', '93.59'] loss: 0.19
========== Round 242 ==========
server, accuracy: 93.26, exits:['91.88', '93.71', '93.77', '93.69'] loss: 0.19
